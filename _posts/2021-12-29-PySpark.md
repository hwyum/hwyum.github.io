---
title: "PySpark 자주 사용하는 문법 정리"
date: 2021-12-29
tags: python
categories: python spark PySpark
---

주의: 아래 내용은 `PySpark 2.4.5` version 기준으로 작성되었습니다. 

# 1. groupBy aggregation 연산

특정 컬럼으로 groupBy 후, 다른 컬럼에 대한 distinct한 count값을 얻고 싶은 경우

```python
df = y.groupBy("year").agg(countDistinct("id"))
df.show()
```



groupBy 후 특정 컬럼에 대한 sum 값을 얻고 싶은 경우

```python
df = y.groupBy("year").agg(sum("count"))
df.show()
```



# 2. selectExpr

select문을 보다 풍부한 표현식과 함께 사용할 수 있는 방법

## 

# 3. Column명 변경

`withColumnRenamed()` 함수를 통해 컬럼명 변경 가능



# 4. approxQuantile

percentile값을 알고 싶을 때 사용할 수 있는 함수입니다. 

```python
# percentile 0.8, 0.9, 0.99 값을 알고 싶은 ㄱㅕㅇ우
df.approxQuantile('duration', [0.8, 0.9, 0.95, 0.99], relativeError=0.001)
```

